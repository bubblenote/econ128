{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression using Scikit-Learn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, a little bit about Linear regression. Linear regression, or ordinary least squares (OLS), is the simplest and most calssic linear method for regression. Linear regression finds the parameters w and b that minimize the mean squared error between predictions and the true regression targets, y, on the training set. The mean square error is the sum of the squared differences between the predictions and the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mississippi', 'Northern Mariana Islands', 'Oklahoma', 'Wyoming', 'Minnesota', 'Alaska', 'American Samoa', 'Arkansas', 'New Mexico', 'Indiana', 'Maryland', 'Louisiana', 'Texas', 'Tennessee', 'Iowa', 'Wisconsin', 'Arizona', 'Michigan', 'Kansas', 'Utah', 'Virginia', 'Oregon', 'Connecticut', 'District of Columbia', 'New Hampshire', 'Idaho', 'West Virginia', 'South Carolina', 'California', 'Massachusetts', 'Vermont', 'Georgia', 'North Dakota', 'Pennsylvania', 'Puerto Rico', 'Florida', 'Hawaii', 'Kentucky', 'Rhode Island', 'Nebraska', 'Missouri', 'Ohio', 'Alabama', 'Illinois', 'Virgin Islands', 'South Dakota', 'Colorado', 'New Jersey', 'National', 'Washington', 'North Carolina', 'Maine', 'New York', 'Montana', 'Nevada', 'Delaware', 'Guam']\n"
     ]
    }
   ],
   "source": [
    "# lets build a dictionary where stateName = key, and abbreviation = value \n",
    "states_abbrev_dict = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "abbrev_states_dict = {v: k for k, v in states_abbrev_dict.items()}\n",
    "print abbrev_states_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, a bit about scikit-learn\n",
    "\n",
    "The structure of scikit-learn:\n",
    "\n",
    "Some of the following text is taken from the scikit-learn API paper: http://arxiv.org/pdf/1309.0238v1.pdf\n",
    "\n",
    ">All objects within scikit-learn share a uniform common basic API consisting of\n",
    "three complementary interfaces: an estimator interface for building and ﬁtting\n",
    "models, a predictor interface for making predictions and a transformer interface\n",
    "for converting data.\n",
    "\n",
    ">The estimator interface is at the core of the library. It deﬁnes instantiation\n",
    "mechanisms of objects and exposes a ***fit*** method for learning a model from\n",
    "training data. All supervised and unsupervised learning algorithms (e.g., for\n",
    "classiﬁcation, regression or clustering) are oﬀered as objects implementing this\n",
    "interface. Machine learning tasks like feature extraction, feature selection or\n",
    "dimensionality reduction are also provided as estimators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example along these lines:\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "   \n",
    "\n",
    ">The **predictor** interface extends the notion of an estimator by adding a predict\n",
    "method that takes an array `X_test` and produces predictions for `X_test`, based on\n",
    "the learned parameters of the estimator. In the case of\n",
    "supervised learning estimators, this method typically returns the predicted values computed by the model. \n",
    "\n",
    "    model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Linear Regression \n",
    "\n",
    "Lets consider a linear regression problem. Let us load the census data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>per_black</th>\n",
       "      <th>per_hisp</th>\n",
       "      <th>per_white</th>\n",
       "      <th>educ_hs</th>\n",
       "      <th>educ_coll</th>\n",
       "      <th>average_income</th>\n",
       "      <th>median_income</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>vote_pop</th>\n",
       "      <th>older_pop</th>\n",
       "      <th>per_older</th>\n",
       "      <th>per_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>26.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>81.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>22984</td>\n",
       "      <td>42081</td>\n",
       "      <td>94.4</td>\n",
       "      <td>3.001712e+06</td>\n",
       "      <td>672383.600</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>63.7</td>\n",
       "      <td>90.7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30726</td>\n",
       "      <td>66521</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.755484e+05</td>\n",
       "      <td>58540.158</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>57.4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>25680</td>\n",
       "      <td>50448</td>\n",
       "      <td>56.3</td>\n",
       "      <td>3.934881e+06</td>\n",
       "      <td>920515.710</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>74.2</td>\n",
       "      <td>81.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>21274</td>\n",
       "      <td>39267</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.798043e+06</td>\n",
       "      <td>428944.934</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>6.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>39.7</td>\n",
       "      <td>80.7</td>\n",
       "      <td>30.1</td>\n",
       "      <td>29188</td>\n",
       "      <td>60883</td>\n",
       "      <td>239.1</td>\n",
       "      <td>2.400975e+07</td>\n",
       "      <td>4409953.704</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  per_black  per_hisp  per_white  educ_hs  educ_coll  \\\n",
       "0     ALABAMA       26.5       4.0       66.8     81.4       21.7   \n",
       "1      ALASKA        3.6       5.8       63.7     90.7       27.0   \n",
       "2     ARIZONA        4.5      30.1       57.4     85.0       26.3   \n",
       "3    ARKANSAS       15.6       6.6       74.2     81.9       19.1   \n",
       "4  CALIFORNIA        6.6      38.1       39.7     80.7       30.1   \n",
       "\n",
       "   average_income  median_income  pop_density      vote_pop    older_pop  \\\n",
       "0           22984          42081         94.4  3.001712e+06   672383.600   \n",
       "1           30726          66521          1.2  4.755484e+05    58540.158   \n",
       "2           25680          50448         56.3  3.934881e+06   920515.710   \n",
       "3           21274          39267         56.0  1.798043e+06   428944.934   \n",
       "4           29188          60883        239.1  2.400975e+07  4409953.704   \n",
       "\n",
       "   per_older  per_vote  \n",
       "0      0.140     0.625  \n",
       "1      0.081     0.658  \n",
       "2      0.142     0.607  \n",
       "3      0.146     0.612  \n",
       "4      0.117     0.637  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data = pd.read_csv(\"./data/census_demographics.csv\")\n",
    "census_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data set, and have it indexed by the state abbrev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per_black</th>\n",
       "      <th>per_hisp</th>\n",
       "      <th>per_white</th>\n",
       "      <th>educ_hs</th>\n",
       "      <th>educ_coll</th>\n",
       "      <th>average_income</th>\n",
       "      <th>median_income</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>vote_pop</th>\n",
       "      <th>older_pop</th>\n",
       "      <th>per_older</th>\n",
       "      <th>per_vote</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>26.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>81.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>22984</td>\n",
       "      <td>42081</td>\n",
       "      <td>94.4</td>\n",
       "      <td>3.001712e+06</td>\n",
       "      <td>672383.600</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>3.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>63.7</td>\n",
       "      <td>90.7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30726</td>\n",
       "      <td>66521</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.755484e+05</td>\n",
       "      <td>58540.158</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>4.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>57.4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>25680</td>\n",
       "      <td>50448</td>\n",
       "      <td>56.3</td>\n",
       "      <td>3.934881e+06</td>\n",
       "      <td>920515.710</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>15.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>74.2</td>\n",
       "      <td>81.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>21274</td>\n",
       "      <td>39267</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.798043e+06</td>\n",
       "      <td>428944.934</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>6.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>39.7</td>\n",
       "      <td>80.7</td>\n",
       "      <td>30.1</td>\n",
       "      <td>29188</td>\n",
       "      <td>60883</td>\n",
       "      <td>239.1</td>\n",
       "      <td>2.400975e+07</td>\n",
       "      <td>4409953.704</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       per_black  per_hisp  per_white  educ_hs  educ_coll  average_income  \\\n",
       "state                                                                       \n",
       "AL          26.5       4.0       66.8     81.4       21.7           22984   \n",
       "AK           3.6       5.8       63.7     90.7       27.0           30726   \n",
       "AZ           4.5      30.1       57.4     85.0       26.3           25680   \n",
       "AR          15.6       6.6       74.2     81.9       19.1           21274   \n",
       "CA           6.6      38.1       39.7     80.7       30.1           29188   \n",
       "\n",
       "       median_income  pop_density      vote_pop    older_pop  per_older  \\\n",
       "state                                                                     \n",
       "AL             42081         94.4  3.001712e+06   672383.600      0.140   \n",
       "AK             66521          1.2  4.755484e+05    58540.158      0.081   \n",
       "AZ             50448         56.3  3.934881e+06   920515.710      0.142   \n",
       "AR             39267         56.0  1.798043e+06   428944.934      0.146   \n",
       "CA             60883        239.1  2.400975e+07  4409953.704      0.117   \n",
       "\n",
       "       per_vote  \n",
       "state            \n",
       "AL        0.625  \n",
       "AK        0.658  \n",
       "AZ        0.607  \n",
       "AR        0.612  \n",
       "CA        0.637  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def capitalize(s):\n",
    "    s = s.title()\n",
    "    return s\n",
    "\n",
    "\n",
    "census_data[\"state\"] = census_data.state.map(capitalize) # for each item in list, apply function 'capitalize' \n",
    "\n",
    "# replace state name with its abbrevation using the dictionary 'abbrev_states_dict'\n",
    "\n",
    "census_data['state']=census_data['state'].replace(abbrev_states_dict)\n",
    "census_data.set_index(\"state\", inplace=True)\n",
    "census_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a scatterplot matrix (refered to as SPLOM) to visualize some columns of this dataset. In Panda's the SPLOM is a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from census_data, extract subset of columns of interest \n",
    "\n",
    "smaller_frame=census_data[['educ_coll', 'average_income', 'per_vote']]\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "axeslist=scatter_matrix(smaller_frame, alpha=0.8, c=\"b\", figsize=(12, 12), diagonal=\"kde\")\n",
    "for ax in axeslist.flatten():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `average_income` seems to have a strong correlation with `educ_coll`. Lets try and regress the former against the latter. One might expect that the average income is higher in states which have \"better\" education systems and send more students to college. First lets confirm our intuition by seeing the co-relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>educ_coll</th>\n",
       "      <th>average_income</th>\n",
       "      <th>per_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>educ_coll</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894066</td>\n",
       "      <td>0.670977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_income</th>\n",
       "      <td>0.894066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_vote</th>\n",
       "      <td>0.670977</td>\n",
       "      <td>0.732703</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                educ_coll  average_income  per_vote\n",
       "educ_coll        1.000000        0.894066  0.670977\n",
       "average_income   0.894066        1.000000  0.732703\n",
       "per_vote         0.670977        0.732703  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_frame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We carry out the regression, first standardizing our variables ( subtract the mean and divide by the standard deviation). This is not necessary, but its a good idea anyway. Since `scikit-learn` wants a `n_sample` rows times `n_features` matrix, we need to reshape the `x` variable. We store both an `_vec` variable, which is easier to plot with, as well as the reshaped variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df_nonNormalized =smaller_frame[['educ_coll', 'average_income']].values\n",
    "df_normalized=(df_nonNormalized - df_nonNormalized.mean(axis=0))/df_nonNormalized.std(axis=0)\n",
    "\n",
    "educ_coll_std_vec=df_normalized[:,0]\n",
    "educ_coll_std=educ_coll_std_vec.reshape(-1,1)\n",
    "\n",
    "average_income_std_vec=df_normalized[:,1]\n",
    "average_income_std=average_income_std_vec.reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We split the data into a training set and a testing set. By default, 25% of the data is reserved for testing. This is the first of multiple ways that we will see to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(educ_coll_std, average_income_std_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the training set for the fit, and find what our predictions ought to be on both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Perform prediction on the test data\n",
    "predicted_train = model.predict(X_train)\n",
    "predicted_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "trains=X_train.reshape(1,-1).flatten()\n",
    "tests=X_test.reshape(1,-1).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"slope\" parameters (w), also called weights or coefficients, are stored in the coef_ attribute, while the offset or intercept (b) is stored in the intercept_ attribute.\n",
    "\n",
    "The intercept_ attribute is alwas a single float number, while the coef_ attribute is a NumPy array with one entry per input feature. As we only have a single input feature, we have only a single entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: [ 0.8351184]\n",
      "Intercept: -0.0389260611515\n"
     ]
    }
   ],
   "source": [
    "print \"Coeff:\", model.coef_\n",
    "print \"Intercept:\",  model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the scatter against the fit for both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9adae46b50>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAF1CAYAAAAugHQnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9P8OUCxQng9fTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ae0035710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(educ_coll_std_vec, average_income_std_vec,c='r') # will plot on same figure \n",
    "plt.plot(trains, predicted_train, c='g', alpha=0.5)  # line \n",
    "plt.plot(tests, predicted_test, c='b', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then look at the residuals, again on both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10eea3610>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(predicted_test, predicted_test- y_test, c='g', s=40)\n",
    "plt.scatter(predicted_train, predicted_train- y_train, c='b', s=40, alpha=0.5)\n",
    "plt.plot([0.4,2],[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask scikit-learn to spit out the $R^2$, which provides the accuracy of the model on the training and testing dataset. If we find the $R^2$ is high for the training dataset, but low for the testing dataset, then that implies that the model was overfitting.... esentially, learning the patterns on the training dataset and not generalizing well on other datatsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81057859819056099, 0.74693264409200921)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train), model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Try to reapply linear regression on a larger portion of the dataset. Recall, we only considered the features 'eduo_call' and 'average_income'.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
